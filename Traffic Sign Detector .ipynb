{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FOLDER 0\n",
      "FOLDER 1\n",
      "FOLDER 2\n",
      "FOLDER 3\n",
      "FOLDER 4\n",
      "FOLDER 5\n",
      "FOLDER 6\n",
      "FOLDER 7\n",
      "FOLDER 8\n",
      "FOLDER 9\n",
      "FOLDER 10\n",
      "FOLDER 11\n",
      "FOLDER 12\n",
      "FOLDER 13\n",
      "FOLDER 14\n",
      "FOLDER 15\n",
      "FOLDER 16\n",
      "FOLDER 17\n",
      "FOLDER 18\n",
      "FOLDER 19\n",
      "FOLDER 20\n",
      "FOLDER 21\n",
      "FOLDER 22\n",
      "FOLDER 23\n",
      "FOLDER 24\n",
      "FOLDER 25\n",
      "FOLDER 26\n",
      "FOLDER 27\n",
      "FOLDER 28\n",
      "FOLDER 29\n",
      "FOLDER 30\n",
      "FOLDER 31\n",
      "FOLDER 32\n",
      "FOLDER 33\n",
      "FOLDER 34\n",
      "FOLDER 35\n",
      "FOLDER 36\n",
      "FOLDER 37\n",
      "FOLDER 38\n",
      "FOLDER 39\n",
      "FOLDER 40\n",
      "FOLDER 41\n",
      "FOLDER 42\n"
     ]
    }
   ],
   "source": [
    "features=[]\n",
    "target=[]\n",
    "for x in range(0,43):\n",
    "    totfolder=os.listdir(\"E:/Datasets/traffic sign\" + \"/\" + str(x))\n",
    "    for y in totfolder:\n",
    "        image=cv2.imread(\"E:/Datasets/traffic sign\" + \"/\" + str(x) + \"/\" + y)\n",
    "        features.append(image)\n",
    "        target.append(x)\n",
    "    print(\"FOLDER\" , x)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "features=np.array(features)\n",
    "target=np.array(target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(34799, 32, 32, 3)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(34799,)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "fea_train, fea_test, tar_train, tar_test = train_test_split(features,target,test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def processing(image):\n",
    "    \n",
    "    image = cv2.cvtColor(image,cv2.COLOR_BGR2GRAY)\n",
    "    image = image/255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6960, 32, 32, 3)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fea_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6960,)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tar_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(27839,)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tar_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(27839, 32, 32, 3)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fea_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocessing(image):\n",
    "    image=cv2.cvtColor(image,cv2.COLOR_BGR2GRAY)\n",
    "    image=image/255\n",
    "\n",
    "    \n",
    "    \n",
    "    return image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "fea_train=np.array(list(map(preprocessing,fea_train)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(27839, 32, 32)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fea_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "fea_train=fea_train.reshape(27839, 32, 32, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.preprocessing.image import ImageDataGenerator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataGen=ImageDataGenerator(rotation_range=10,width_shift_range=0.1,height_shift_range=0.1,zoom_range=0.2,shear_range=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataGen.fit(fea_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "batches=dataGen.flow(fea_train,tar_train,batch_size=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1392"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(batches)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "images,labels=next(batches)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(20, 32, 32, 1)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "images.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(20,)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.utils import to_categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "tar_train = to_categorical(tar_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(27839, 43)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tar_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(27839, 32, 32, 1)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fea_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import Dense,Flatten,Conv2D,MaxPooling2D,Dropout\n",
    "from keras.models import Sequential\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "model=Sequential()\n",
    "model.add(Conv2D(60,(3,3),activation=\"relu\",input_shape=(32,32,1)))\n",
    "model.add(Conv2D(60,(3,3),activation=\"relu\"))\n",
    "model.add(MaxPooling2D((2,2)))\n",
    "model.add(Conv2D(30,(3,3),activation=\"relu\"))\n",
    "model.add(Conv2D(30,(3,3),activation=\"relu\"))\n",
    "model.add(Conv2D(30,(3,3),activation=\"relu\"))\n",
    "model.add(MaxPooling2D((2,2)))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(500,activation=\"relu\"))\n",
    "model.add(Dense(43,activation=\"softmax\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.optimizers import Adam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(Adam(lr=0.001),loss=\"categorical_crossentropy\",metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Sakthivel\\anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py:1844: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
      "  warnings.warn('`Model.fit_generator` is deprecated and '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "1392/1392 [==============================] - 71s 51ms/step - loss: 3.1208 - accuracy: 0.1583\n",
      "Epoch 2/20\n",
      "1392/1392 [==============================] - 70s 51ms/step - loss: 0.9839 - accuracy: 0.7050\n",
      "Epoch 3/20\n",
      "1392/1392 [==============================] - 70s 50ms/step - loss: 0.5787 - accuracy: 0.8234\n",
      "Epoch 4/20\n",
      "1392/1392 [==============================] - 70s 51ms/step - loss: 0.4157 - accuracy: 0.8728\n",
      "Epoch 5/20\n",
      "1392/1392 [==============================] - 69s 50ms/step - loss: 0.3185 - accuracy: 0.9031\n",
      "Epoch 6/20\n",
      "1392/1392 [==============================] - 69s 50ms/step - loss: 0.2849 - accuracy: 0.9145\n",
      "Epoch 7/20\n",
      "1392/1392 [==============================] - 72s 52ms/step - loss: 0.2595 - accuracy: 0.9235\n",
      "Epoch 8/20\n",
      "1392/1392 [==============================] - 75s 54ms/step - loss: 0.2213 - accuracy: 0.9313\n",
      "Epoch 9/20\n",
      "1392/1392 [==============================] - 70s 50ms/step - loss: 0.2068 - accuracy: 0.9373\n",
      "Epoch 10/20\n",
      "1392/1392 [==============================] - 69s 50ms/step - loss: 0.1794 - accuracy: 0.9446\n",
      "Epoch 11/20\n",
      "1392/1392 [==============================] - 70s 50ms/step - loss: 0.1701 - accuracy: 0.9487\n",
      "Epoch 12/20\n",
      "1392/1392 [==============================] - 70s 50ms/step - loss: 0.1508 - accuracy: 0.9540\n",
      "Epoch 13/20\n",
      "1392/1392 [==============================] - 70s 50ms/step - loss: 0.1638 - accuracy: 0.9509\n",
      "Epoch 14/20\n",
      "1392/1392 [==============================] - 70s 50ms/step - loss: 0.1457 - accuracy: 0.9555\n",
      "Epoch 15/20\n",
      "1392/1392 [==============================] - 70s 50ms/step - loss: 0.1391 - accuracy: 0.95900s - loss: 0.1391 - accura\n",
      "Epoch 16/20\n",
      "1392/1392 [==============================] - 76s 55ms/step - loss: 0.1427 - accuracy: 0.9569\n",
      "Epoch 17/20\n",
      "1392/1392 [==============================] - 78s 56ms/step - loss: 0.1282 - accuracy: 0.9617\n",
      "Epoch 18/20\n",
      "1392/1392 [==============================] - 78s 56ms/step - loss: 0.1285 - accuracy: 0.9642\n",
      "Epoch 19/20\n",
      "1392/1392 [==============================] - 71s 51ms/step - loss: 0.1154 - accuracy: 0.9651\n",
      "Epoch 20/20\n",
      "1392/1392 [==============================] - 71s 51ms/step - loss: 0.1258 - accuracy: 0.9624\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x1be8dbed8b0>"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit_generator(dataGen.flow(fea_train,tar_train,batch_size=20),epochs=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import model_from_json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Save the Model\n"
     ]
    }
   ],
   "source": [
    "model_json=model.to_json()\n",
    "with open(\"verzeoAITraffic.json\",\"w\") as abc:\n",
    "    abc.write(model_json)\n",
    "    abc.close()\n",
    "model.save_weights(\"verzeoAITrafficWeights.h5\")\n",
    "print(\"Save the Model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded Model Sucesssfully\n"
     ]
    }
   ],
   "source": [
    "json_file=open(\"verzeoAITraffic.json\",\"r\")\n",
    "loaded_model_json=json_file.read()\n",
    "json_file.close()\n",
    "loaded_model=model_from_json(loaded_model_json)\n",
    "loaded_model.load_weights(\"verzeoAITrafficWeights.h5\")\n",
    "print(\"Loaded Model Sucesssfully\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getClassName(classNo):\n",
    "    if   classNo == 0: return 'Speed Limit 20 km/h'\n",
    "    elif classNo == 1: return 'Speed Limit 30 km/h'\n",
    "    elif classNo == 2: return 'Speed Limit 50 km/h'\n",
    "    elif classNo == 3: return 'Speed Limit 60 km/h'\n",
    "    elif classNo == 4: return 'Speed Limit 70 km/h'\n",
    "    elif classNo == 5: return 'Speed Limit 80 km/h'\n",
    "    elif classNo == 6: return 'End of Speed Limit 80 km/h'\n",
    "    elif classNo == 7: return 'Speed Limit 100 km/h'\n",
    "    elif classNo == 8: return 'Speed Limit 120 km/h'\n",
    "    elif classNo == 9: return 'No passing'\n",
    "    elif classNo == 10: return 'No passing for vechiles over 3.5 metric tons'\n",
    "    elif classNo == 11: return 'Right-of-way at the next intersection'\n",
    "    elif classNo == 12: return 'Priority road'\n",
    "    elif classNo == 13: return 'Yield'\n",
    "    elif classNo == 14: return 'Stop'\n",
    "    elif classNo == 15: return 'No vechiles'\n",
    "    elif classNo == 16: return 'Vechiles over 3.5 metric tons prohibited'\n",
    "    elif classNo == 17: return 'No entry'\n",
    "    elif classNo == 18: return 'General caution'\n",
    "    elif classNo == 19: return 'Dangerous curve to the left'\n",
    "    elif classNo == 20: return 'Dangerous curve to the right'\n",
    "    elif classNo == 21: return 'Double curve'\n",
    "    elif classNo == 22: return 'Bumpy road'\n",
    "    elif classNo == 23: return 'Slippery road'\n",
    "    elif classNo == 24: return 'Road narrows on the right'\n",
    "    elif classNo == 25: return 'Road work'\n",
    "    elif classNo == 26: return 'Traffic signals'\n",
    "    elif classNo == 27: return 'Pedestrians'\n",
    "    elif classNo == 28: return 'Children crossing'\n",
    "    elif classNo == 29: return 'Bicycles crossing'\n",
    "    elif classNo == 30: return 'Beware of ice/snow'\n",
    "    elif classNo == 31: return 'Wild animals crossing'\n",
    "    elif classNo == 32: return 'End of all speed and passing limits'\n",
    "    elif classNo == 33: return 'Turn right ahead'\n",
    "    elif classNo == 34: return 'Turn left ahead'\n",
    "    elif classNo == 35: return 'Ahead only'\n",
    "    elif classNo == 36: return 'Go straight or right'\n",
    "    elif classNo == 37: return 'Go straight or left'\n",
    "    elif classNo == 38: return 'Keep right'\n",
    "    elif classNo == 39: return 'Keep left'\n",
    "    elif classNo == 40: return 'Roundabout mandatory'\n",
    "    elif classNo == 41: return 'End of no passing'\n",
    "    elif classNo == 42: return 'End of no passing by vechiles over 3.5 metric tons'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "capt=cv2.VideoCapture(0)\n",
    "capt.set(3,640)\n",
    "capt.set(4,480)\n",
    "capt.set(10,180)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Sakthivel\\anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\sequential.py:450: UserWarning: `model.predict_classes()` is deprecated and will be removed after 2021-01-01. Please use instead:* `np.argmax(model.predict(x), axis=-1)`,   if your model does multi-class classification   (e.g. if it uses a `softmax` last-layer activation).* `(model.predict(x) > 0.5).astype(\"int32\")`,   if your model does binary classification   (e.g. if it uses a `sigmoid` last-layer activation).\n",
      "  warnings.warn('`model.predict_classes()` is deprecated and '\n"
     ]
    }
   ],
   "source": [
    "while True:\n",
    "    message,image=capt.read()\n",
    "    imagearr=np.asarray(image)\n",
    "    imagearr=cv2.resize(imagearr,(32,32))\n",
    "    imagearr=preprocessing(imagearr)\n",
    "    imagearr=imagearr.reshape(1,32,32,1)\n",
    "    predictions=loaded_model.predict(imagearr)\n",
    "    classIndex=loaded_model.predict_classes(imagearr)\n",
    "    cv2.putText(image,\"Class: \",(20,35),cv2.FONT_HERSHEY_SIMPLEX,1,(0,0,255),2)\n",
    "    cv2.putText(image,\"Probability: \",(20,75),cv2.FONT_HERSHEY_SIMPLEX,1,(0,0,255),2)\n",
    "    probabilityValue=np.amax(predictions)\n",
    "    if probabilityValue>0.75:\n",
    "        cv2.putText(image,getClassName(classIndex),(120 , 35),cv2.FONT_HERSHEY_SIMPLEX,1,(0,0,255),2)\n",
    "        cv2.putText(image,str(int(probabilityValue * 100)) + \" %\",( 200,75),cv2.FONT_HERSHEY_SIMPLEX,1,(0,0,255),2)\n",
    "    cv2.imshow(\"Model Prediction\",image)\n",
    "    returnedValue=cv2.waitKey(1)\n",
    "    if returnedValue==ord(\"s\") or returnedValue==ord(\"S\"):\n",
    "        cv2.destroyAllWindows()\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
